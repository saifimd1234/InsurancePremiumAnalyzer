{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a86e3cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29f30a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. SETUP: Define your data and output directories ---\n",
    "# Please ensure these paths are correct for your system.\n",
    "BASE_DIR = os.getcwd() \n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"output\")\n",
    "\n",
    "# --- Helper function for cleaning numeric values ---\n",
    "def clean_value(text):\n",
    "    \"\"\"\n",
    "    Cleans a string to extract a numeric value.\n",
    "    Removes commas, handles None, and converts to integer.\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return 0\n",
    "    # Remove commas, newlines, and other non-numeric characters\n",
    "    cleaned_text = re.sub(r'[^\\d.-]', '', str(text))\n",
    "    if not cleaned_text or cleaned_text == '-':\n",
    "        return 0\n",
    "    try:\n",
    "        # Convert to float first to handle decimals, then to int\n",
    "        return int(float(cleaned_text))\n",
    "    except (ValueError, TypeError):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c009d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. THE PARSER: Function to handle the new table format ---\n",
    "def parse_nl4_new_format(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts Health, Personal Accident, and Travel premium data from a FORM NL-4 PDF \n",
    "    where headers are at the bottom and span multiple columns.\n",
    "    \"\"\"\n",
    "    provider = \"Unknown\"\n",
    "    # Map report month to financial quarter\n",
    "    month_map = {\n",
    "        'june': 'Q1', 'jun': 'Q1',\n",
    "        'september': 'Q2', 'sep': 'Q2',\n",
    "        'december': 'Q3', 'dec': 'Q3',\n",
    "        'march': 'Q4', 'mar': 'Q4'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            # 1. Extract Provider Name from the first page (reusing robust logic)\n",
    "            if pdf.pages:\n",
    "                first_page_text = pdf.pages[0].extract_text(x_tolerance=2) or \"\"\n",
    "                # Regex to find company names like 'Aditya Birla Health Insurance Co. Limited'\n",
    "                m = re.search(r\"([A-Za-z\\s&.()]+(?:Insurance|Assurance)[\\s]+(?:Company\\s)?(?:Ltd|Limited)\\.?)\", first_page_text, re.IGNORECASE)\n",
    "                if m:\n",
    "                    provider = \" \".join(m.group(1).strip().split()) # Clean up whitespace\n",
    "                else: # Fallback logic\n",
    "                    for line in first_page_text.splitlines():\n",
    "                        if \"Insurance\" in line and (\"Ltd\" in line or \"Limited\" in line):\n",
    "                             m = re.search(r\"([A-Za-z &]+Insurance[^,\\n]*)\", line)\n",
    "                             if m:\n",
    "                                 provider = m.group(1).strip()\n",
    "                                 break\n",
    "\n",
    "            # 2. Find and process the NL-4 page\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text(x_tolerance=2) or \"\"\n",
    "                if \"FORM NL-4\" not in page_text or \"PREMIUM SCHEDULE\" not in page_text:\n",
    "                    continue\n",
    "\n",
    "                # 3. Extract Year and Quarter from the report's title\n",
    "                year, quarter = None, None\n",
    "                date_match = re.search(r\"For the\\s+Quarter\\s+([A-Za-z]+),\\s*(\\d{4})\", page_text, re.IGNORECASE)\n",
    "                if date_match:\n",
    "                    month_str, year_str = date_match.group(1).lower(), date_match.group(2)\n",
    "                    year = int(year_str)\n",
    "                    for key, q_val in month_map.items():\n",
    "                        if month_str.startswith(key):\n",
    "                            quarter = q_val\n",
    "                            break\n",
    "                    # For financial year, March quarter belongs to the previous calendar year\n",
    "                    if quarter == 'Q4':\n",
    "                        year -= 1\n",
    "                \n",
    "                if not year or not quarter:\n",
    "                    continue # Skip page if date can't be determined\n",
    "\n",
    "                # 4. Extract table data from the page\n",
    "                table = page.extract_table({\n",
    "                    \"vertical_strategy\": \"lines\",\n",
    "                    \"horizontal_strategy\": \"text\",\n",
    "                    \"text_x_tolerance\": 2,\n",
    "                    \"text_y_tolerance\": 2,\n",
    "                })\n",
    "                if not table:\n",
    "                    continue\n",
    "\n",
    "                # 5. Find header row and map header text to column indices\n",
    "                header_indices = {}\n",
    "                header_row_found = False\n",
    "                # Search from the bottom of the table upwards\n",
    "                for r in reversed(table):\n",
    "                    row_str = \" \".join(filter(None, [str(s).replace('\\n', ' ') for s in r]))\n",
    "                    if \"Personal Accident\" in row_str and \"Total Health\" in row_str and \"Travel Insurance\" in row_str:\n",
    "                        for i, cell in enumerate(r):\n",
    "                            if cell:\n",
    "                                clean_cell = cell.replace('\\n', ' ').strip()\n",
    "                                if clean_cell == \"Health\": header_indices['health'] = i\n",
    "                                elif clean_cell == \"Personal Accident\": header_indices['personal_accident'] = i\n",
    "                                elif clean_cell == \"Travel Insurance\": header_indices['travel'] = i\n",
    "                                elif clean_cell == \"Total Health\": header_indices['total'] = i\n",
    "                        \n",
    "                        if len(header_indices) >= 3:\n",
    "                           header_row_found = True\n",
    "                           break\n",
    "                \n",
    "                if not header_row_found:\n",
    "                    continue # Headers not found on this page\n",
    "\n",
    "                # 6. Find the 'Gross Direct Premium' row and extract values\n",
    "                for r in table:\n",
    "                    if r and r[0] and \"Gross Direct Premium\" in str(r[0]):\n",
    "                        # Extract data using the mapped indices. The index points to the \n",
    "                        # 'For the Quarter' column, which is the first of each pair.\n",
    "                        health_val = clean_value(r[header_indices.get('health')])\n",
    "                        pa_val = clean_value(r[header_indices.get('personal_accident')])\n",
    "                        travel_val = clean_value(r[header_indices.get('travel')])\n",
    "                        total_val = clean_value(r[header_indices.get('total')])\n",
    "\n",
    "                        # Return the final dictionary\n",
    "                        return {\n",
    "                            \"provider\": provider,\n",
    "                            \"year\": year,\n",
    "                            \"quarter\": quarter,\n",
    "                            \"health\": health_val,\n",
    "                            \"personal_accident\": pa_val,\n",
    "                            \"travel\": travel_val,\n",
    "                            \"total\": total_val, # This comes from the 'Total Health' column\n",
    "                            \"source_file\": os.path.basename(pdf_path)\n",
    "                        }\n",
    "                # If loop finishes, the target row was not found on this page\n",
    "    except Exception as e:\n",
    "        print(f\"  -> An error occurred while processing {os.path.basename(pdf_path)}: {e}\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfcd00e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Processing: Q1 2024.pdf\n",
      "❌ Failed to extract data from: Q1 2024.pdf\n",
      "📄 Processing: Q1 2025.pdf\n",
      "❌ Failed to extract data from: Q1 2025.pdf\n",
      "📄 Processing: Q1 FY 23.pdf\n",
      "❌ Failed to extract data from: Q1 FY 23.pdf\n",
      "📄 Processing: Q2 2024.pdf\n",
      "❌ Failed to extract data from: Q2 2024.pdf\n",
      "📄 Processing: Q2 2025.pdf\n",
      "❌ Failed to extract data from: Q2 2025.pdf\n",
      "📄 Processing: Q2 FY 23.pdf\n",
      "❌ Failed to extract data from: Q2 FY 23.pdf\n",
      "📄 Processing: Q3 2024.pdf\n",
      "❌ Failed to extract data from: Q3 2024.pdf\n",
      "📄 Processing: Q3 2025.pdf\n",
      "❌ Failed to extract data from: Q3 2025.pdf\n",
      "📄 Processing: Q3 FY 23.pdf\n",
      "❌ Failed to extract data from: Q3 FY 23.pdf\n",
      "📄 Processing: Q4 2024.pdf\n",
      "❌ Failed to extract data from: Q4 2024.pdf\n",
      "📄 Processing: Q4 2025.pdf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m📄 Processing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.path.basename(pdf_file)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Use the new parsing function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m result = \u001b[43mparse_nl4_new_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Extracted: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mprovider\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mquarter\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mparse_nl4_new_format\u001b[39m\u001b[34m(pdf_path)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# 2. Find and process the NL-4 page\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pdf.pages:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     page_text = \u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mFORM NL-4\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m page_text \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mPREMIUM SCHEDULE\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m page_text:\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saifi\\GitHub\\InsurancePremiumAnalyzer\\venv\\Lib\\site-packages\\pdfplumber\\page.py:530\u001b[39m, in \u001b[36mPage.extract_text\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_textmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtuplify_list_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.as_string\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saifi\\GitHub\\InsurancePremiumAnalyzer\\venv\\Lib\\site-packages\\pdfplumber\\page.py:507\u001b[39m, in \u001b[36mPage._get_textmap\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    505\u001b[39m     defaults.update({\u001b[33m\"\u001b[39m\u001b[33mlayout_height\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.height})\n\u001b[32m    506\u001b[39m full_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] = {**defaults, **kwargs}\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m utils.chars_to_textmap(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchars\u001b[49m, **full_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saifi\\GitHub\\InsurancePremiumAnalyzer\\venv\\Lib\\site-packages\\pdfplumber\\container.py:52\u001b[39m, in \u001b[36mContainer.chars\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchars\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> T_obj_list:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobjects\u001b[49m.get(\u001b[33m\"\u001b[39m\u001b[33mchar\u001b[39m\u001b[33m\"\u001b[39m, [])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saifi\\GitHub\\InsurancePremiumAnalyzer\\venv\\Lib\\site-packages\\pdfplumber\\page.py:346\u001b[39m, in \u001b[36mPage.objects\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_objects\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._objects\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m \u001b[38;5;28mself\u001b[39m._objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._objects\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saifi\\GitHub\\InsurancePremiumAnalyzer\\venv\\Lib\\site-packages\\pdfplumber\\page.py:443\u001b[39m, in \u001b[36mPage.parse_objects\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_objects\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list]:\n\u001b[32m    442\u001b[39m     objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] = {}\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_layout_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayout\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_objs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mobject_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manno\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saifi\\GitHub\\InsurancePremiumAnalyzer\\venv\\Lib\\site-packages\\pdfplumber\\page.py:439\u001b[39m, in \u001b[36mPage.iter_layout_objects\u001b[39m\u001b[34m(self, layout_objects)\u001b[39m\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_layout_objects(obj._objs)\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saifi\\GitHub\\InsurancePremiumAnalyzer\\venv\\Lib\\site-packages\\pdfplumber\\page.py:364\u001b[39m, in \u001b[36mPage.process_object\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    362\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m attr = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mmap\u001b[39m(process_attr, obj.\u001b[34m__dict__\u001b[39m.items())))\n\u001b[32m    366\u001b[39m attr[\u001b[33m\"\u001b[39m\u001b[33mobject_type\u001b[39m\u001b[33m\"\u001b[39m] = kind\n\u001b[32m    367\u001b[39m attr[\u001b[33m\"\u001b[39m\u001b[33mpage_number\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.page_number\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saifi\\GitHub\\InsurancePremiumAnalyzer\\venv\\Lib\\site-packages\\pdfplumber\\page.py:356\u001b[39m, in \u001b[36mPage.process_object.<locals>.process_attr\u001b[39m\u001b[34m(item)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_object\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: LTItem) -> T_obj:\n\u001b[32m    354\u001b[39m     kind = re.sub(lt_pat, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, obj.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m).lower()\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_attr\u001b[39m(item: Tuple[\u001b[38;5;28mstr\u001b[39m, Any]) -> Optional[Tuple[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    357\u001b[39m         k, v = item\n\u001b[32m    358\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m ALL_ATTRS:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- 3. PROCESSING LOOP: Extract data from all PDFs ---\n",
    "records = []\n",
    "failed_files = []\n",
    "\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    print(f\"❌ Error: Data directory not found at '{DATA_DIR}'\")\n",
    "    # As a fallback for demonstration, try to run on the provided attachment.\n",
    "    # NOTE: You should place your PDFs in a 'data' sub-directory for the script to work.\n",
    "    if os.path.exists(\"Q1-2025-5.pdf\"):\n",
    "         DATA_DIR = \".\" \n",
    "    else:\n",
    "        print(\"Please create a 'data' directory and place your PDF files inside it.\")\n",
    "\n",
    "if os.path.isdir(DATA_DIR):\n",
    "    pdf_files = sorted(glob.glob(os.path.join(DATA_DIR, \"*.pdf\")))\n",
    "    if not pdf_files:\n",
    "        print(f\"No PDF files found in '{DATA_DIR}'.\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"📄 Processing: {os.path.basename(pdf_file)}\")\n",
    "        # Use the new parsing function\n",
    "        result = parse_nl4_new_format(pdf_file)\n",
    "        if result:\n",
    "            print(f\"✅ Extracted: {result['provider']}, {result['year']} {result['quarter']}\")\n",
    "            records.append(result)\n",
    "        else:\n",
    "            print(f\"❌ Failed to extract data from: {os.path.basename(pdf_file)}\")\n",
    "            failed_files.append(os.path.basename(pdf_file))\n",
    "\n",
    "    print(f\"\\nTotal successfully extracted: {len(records)}\")\n",
    "    print(f\"Total failed: {len(failed_files)}\")\n",
    "    if failed_files:\n",
    "        print(\"Failed files:\", failed_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32c16ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "🕵️  STARTING DEBUG FOR: Q1 2024.pdf\n",
      "==================================================\n",
      "\n",
      "--- [Step 1: Extracting Provider Name] ---\n",
      "  - Text from first page (first 300 chars):\n",
      "---\n",
      "Applicability\n",
      "S.No. Form No Description General Indian Branches of\n",
      "& Health Reinsurer Foreign\n",
      "Insurers Reinsurer in\n",
      "India\n",
      "1 NL-1-B-RA Revenue Account YES YES YES\n",
      "2 NL-2-B-PL Profit and Loss Account YES YES YES\n",
      "3 NL-3-B-BS Balance Sheet YES YES NO\n",
      "4 NL-4-PREMIUM SCHEDULE Premium YES YES YES\n",
      "5 NL-5-CL\n",
      "---\n",
      "  - Regex failed. Falling back to line-by-line search.\n",
      "  ❌ WARNING: Could not determine provider name.\n",
      "\n",
      "--- [Step 2: Finding 'FORM NL-4 PREMIUM SCHEDULE' Page] ---\n",
      "  - Scanning Page 1...\n",
      "  - Scanning Page 2...\n",
      "  - Scanning Page 3...\n",
      "  - Scanning Page 4...\n",
      "  - Scanning Page 5...\n",
      "  ✅ Found 'FORM NL-4' on Page 5.\n",
      "\n",
      "--- [Step 3: Extracting Quarter and Year] ---\n",
      "  ❌ ERROR: Could not find the date string on the page.\n",
      "\n",
      "--- [Step 4: Extracting Table from Page] ---\n",
      "  ✅ Table found with 1 rows.\n",
      "  - Printing full extracted table for review:\n",
      "                                                                                                                     0                                                                                                         1                                                                                               2                                          3                                                                                                   4                                                                                                         5                                                                                                        6                                                                                         7                                                                                                        8                                                                                           9                                                                                               10                                                                                                                             11                                                                                                           12                                                                                                       13                                                                                  14                                                                                        15                                                                                            16                                                                                                                     17                                                                                                                         18                                                                                                                                      19\n",
      "0  Particulars\\nGross Direct Premium\\nAdd: Premium on reinsurance accepted (a)\\nLess : Premium on reinsurance ceded (a)  FIRE\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n1 ,769 1 ,769\\n3 01 3 01\\n1 ,230 1 ,230  Marine Cargo\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n4 9 4 9\\n- -\\n4 5 4 5  Marine Hull\\nFor the\\nQuarter\\nJune, 2022  Motor OD\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n7 ,296 7 ,296\\n- -\\n3 27 3 27  Motor TP\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n2 9,609 2 9,609\\n- -\\n1 ,505 1 ,505  Total Motor\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n36,904 36,904\\n- -\\n1,832 1,832  Health\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n2 6 2 6\\n- -\\n1 0 1 0  Personal Accident\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n5 78 5 78\\n- -\\n1 67 1 67  Travel Insurance\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n- -\\n- -\\n- -  Total Health\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n604 604\\n- -\\n177 177  Workmen’s Compensation/\\nEmployer’s liability\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n1 11 1 11\\n- -\\n5 5  Public/ Product Liability\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n3 2 3 2\\n- -\\n1 6 1 6  Engineering\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n3 44 3 44\\n1 19 1 19\\n1 90 1 90  Aviation\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n- -\\n- -\\n- -  Crop Insurance\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n- -\\n- -\\n- -  Other segments (b)\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n- -\\n- -\\n- -  Other Miscellaneous segment\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n3 34 3 34\\n2 3 2 3\\n1 51 1 51  Total Miscellaneous\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n3 8,329 3 8,329\\n1 42 1 42\\n2 ,370 2 ,370  Grand Total\\nJu F Q n o u e r a , t r 2 h t 0 e e 2 r 2 Up J t u o n t e h , e 2 q 0 u 2 a 2 rter\\n40,147 40,147\\n443 443\\n3,645 3,645\n",
      "\n",
      "--- [Step 5: Finding Header Row] ---\n",
      "  - Potential header found in table row 0: 'Particulars Gross Direct Premium Add: Premium on reinsurance accepted (a) Less : Premium on reinsurance ceded (a) FIRE For the Up to the Quarter quarter June, 2022 June, 2022 1 ,769 1 ,769 3 01 3 01 1 ,230 1 ,230 Marine Cargo For the Up to the Quarter quarter June, 2022 June, 2022 4 9 4 9 - - 4 5 4 5 Marine Hull For the Quarter June, 2022 Motor OD For the Up to the Quarter quarter June, 2022 June, 2022 7 ,296 7 ,296 - - 3 27 3 27 Motor TP For the Up to the Quarter quarter June, 2022 June, 2022 2 9,609 2 9,609 - - 1 ,505 1 ,505 Total Motor For the Up to the Quarter quarter June, 2022 June, 2022 36,904 36,904 - - 1,832 1,832 Health For the Up to the Quarter quarter June, 2022 June, 2022 2 6 2 6 - - 1 0 1 0 Personal Accident For the Up to the Quarter quarter June, 2022 June, 2022 5 78 5 78 - - 1 67 1 67 Travel Insurance For the Up to the Quarter quarter June, 2022 June, 2022 - - - - - - Total Health For the Up to the Quarter quarter June, 2022 June, 2022 604 604 - - 177 177 Workmen’s Compensation/ Employer’s liability For the Up to the Quarter quarter June, 2022 June, 2022 1 11 1 11 - - 5 5 Public/ Product Liability For the Up to the Quarter quarter June, 2022 June, 2022 3 2 3 2 - - 1 6 1 6 Engineering For the Up to the Quarter quarter June, 2022 June, 2022 3 44 3 44 1 19 1 19 1 90 1 90 Aviation For the Up to the Quarter quarter June, 2022 June, 2022 - - - - - - Crop Insurance For the Up to the Quarter quarter June, 2022 June, 2022 - - - - - - Other segments (b) For the Up to the Quarter quarter June, 2022 June, 2022 - - - - - - Other Miscellaneous segment For the Up to the Quarter quarter June, 2022 June, 2022 3 34 3 34 2 3 2 3 1 51 1 51 Total Miscellaneous For the Up to the Quarter quarter June, 2022 June, 2022 3 8,329 3 8,329 1 42 1 42 2 ,370 2 ,370 Grand Total Ju F Q n o u e r a , t r 2 h t 0 e e 2 r 2 Up J t u o n t e h , e 2 q 0 u 2 a 2 rter 40,147 40,147 443 443 3,645 3,645'\n",
      "\n",
      "--- [Step 6: Finding 'Gross Direct Premium' Data Row] ---\n",
      "  ✅ Found 'Gross Direct Premium' in table row 0.\n",
      "  - Full data row content: ['Particulars\\nGross Direct Premium\\nAdd: Premium on reinsurance accepted (a)\\nLess : Premium on reinsurance ceded (a)', 'FIRE\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n1 ,769 1 ,769\\n3 01 3 01\\n1 ,230 1 ,230', 'Marine Cargo\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n4 9 4 9\\n- -\\n4 5 4 5', 'Marine Hull\\nFor the\\nQuarter\\nJune, 2022', 'Motor OD\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n7 ,296 7 ,296\\n- -\\n3 27 3 27', 'Motor TP\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n2 9,609 2 9,609\\n- -\\n1 ,505 1 ,505', 'Total Motor\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n36,904 36,904\\n- -\\n1,832 1,832', 'Health\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n2 6 2 6\\n- -\\n1 0 1 0', 'Personal Accident\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n5 78 5 78\\n- -\\n1 67 1 67', 'Travel Insurance\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n- -\\n- -\\n- -', 'Total Health\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n604 604\\n- -\\n177 177', 'Workmen’s Compensation/\\nEmployer’s liability\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n1 11 1 11\\n- -\\n5 5', 'Public/ Product Liability\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n3 2 3 2\\n- -\\n1 6 1 6', 'Engineering\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n3 44 3 44\\n1 19 1 19\\n1 90 1 90', 'Aviation\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n- -\\n- -\\n- -', 'Crop Insurance\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n- -\\n- -\\n- -', 'Other segments (b)\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n- -\\n- -\\n- -', 'Other Miscellaneous segment\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n3 34 3 34\\n2 3 2 3\\n1 51 1 51', 'Total Miscellaneous\\nFor the Up to the\\nQuarter quarter\\nJune, 2022 June, 2022\\n3 8,329 3 8,329\\n1 42 1 42\\n2 ,370 2 ,370', 'Grand Total\\nJu F Q n o u e r a , t r 2 h t 0 e e 2 r 2 Up J t u o n t e h , e 2 q 0 u 2 a 2 rter\\n40,147 40,147\\n443 443\\n3,645 3,645']\n",
      "\n",
      "--- [Step 7: Extracting Final Values] ---\n",
      "\n",
      "🚨 A FATAL SCRIPT ERROR OCCURRED: list indices must be integers or slices, not NoneType\n",
      "\n",
      "==================================================\n",
      "🕵️  DEBUGGING COMPLETE\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "# --- 1. SETUP: Define your data and output directories ---\n",
    "BASE_DIR = os.getcwd() \n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "\n",
    "# --- Helper function for cleaning numeric values ---\n",
    "def clean_value(text):\n",
    "    if text is None:\n",
    "        return 0\n",
    "    cleaned_text = re.sub(r'[^\\d.-]', '', str(text))\n",
    "    if not cleaned_text or cleaned_text == '-':\n",
    "        return 0\n",
    "    try:\n",
    "        return int(float(cleaned_text))\n",
    "    except (ValueError, TypeError):\n",
    "        return 0\n",
    "\n",
    "# --- 2. THE DEBUGGING FUNCTION ---\n",
    "def debug_pdf_extraction(pdf_path):\n",
    "    \"\"\"\n",
    "    Runs the extraction process step-by-step and prints detailed\n",
    "    debug information at each stage.\n",
    "    \"\"\"\n",
    "    print(\"=\"*50)\n",
    "    print(f\"🕵️  STARTING DEBUG FOR: {os.path.basename(pdf_path)}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"❌ ERROR: File not found at '{pdf_path}'. Please check the path and filename.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            # --- Step 1: Provider Name Extraction ---\n",
    "            print(\"\\n--- [Step 1: Extracting Provider Name] ---\")\n",
    "            provider = \"Unknown\"\n",
    "            if pdf.pages:\n",
    "                first_page_text = pdf.pages[0].extract_text(x_tolerance=2) or \"\"\n",
    "                print(f\"  - Text from first page (first 300 chars):\\n---\\n{first_page_text[:300]}\\n---\")\n",
    "                m = re.search(r\"([A-Za-z\\s&.()]+(?:Insurance|Assurance)[\\s]+(?:Company\\s)?(?:Ltd|Limited)\\.?)\", first_page_text, re.IGNORECASE)\n",
    "                if m:\n",
    "                    provider = \" \".join(m.group(1).strip().split())\n",
    "                    print(f\"  ✅ Provider found via regex: '{provider}'\")\n",
    "                else:\n",
    "                    print(\"  - Regex failed. Falling back to line-by-line search.\")\n",
    "                    for line in first_page_text.splitlines():\n",
    "                        if \"Insurance\" in line and (\"Ltd\" in line or \"Limited\" in line):\n",
    "                            provider = line.strip()\n",
    "                            print(f\"  ✅ Provider found via fallback: '{provider}'\")\n",
    "                            break\n",
    "            if provider == \"Unknown\":\n",
    "                print(\"  ❌ WARNING: Could not determine provider name.\")\n",
    "\n",
    "            # --- Step 2: Finding the Correct Page ---\n",
    "            print(\"\\n--- [Step 2: Finding 'FORM NL-4 PREMIUM SCHEDULE' Page] ---\")\n",
    "            nl4_page_found = False\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                print(f\"  - Scanning Page {i+1}...\")\n",
    "                page_text = page.extract_text(x_tolerance=2, layout=True) or \"\"\n",
    "                if \"FORM NL-4\" in page_text and \"PREMIUM SCHEDULE\" in page_text:\n",
    "                    nl4_page_found = True\n",
    "                    print(f\"  ✅ Found 'FORM NL-4' on Page {i+1}.\")\n",
    "                    \n",
    "                    # --- Step 3: Date Extraction ---\n",
    "                    print(\"\\n--- [Step 3: Extracting Quarter and Year] ---\")\n",
    "                    year, quarter = None, None\n",
    "                    # Using the robust regex from the previous attempt\n",
    "                    date_match = re.search(r\"For\\s+the\\s+Quarter\\s+(?:Ended\\s*)?(?:on\\s|at\\s)?(?:the\\s)?\\d{0,2}(?:st|nd|rd|th)?\\s*([A-Za-z]+)[, ]+\\s*(\\d{4})\", page_text, re.IGNORECASE)\n",
    "                    if date_match:\n",
    "                        month_str, year_str = date_match.group(1).lower(), date_match.group(2)\n",
    "                        print(f\"  - Date regex match found: Month='{month_str}', Year='{year_str}'\")\n",
    "                        year = int(year_str)\n",
    "                        month_map = {'june': 'Q1', 'september': 'Q2', 'december': 'Q3', 'march': 'Q4'}\n",
    "                        for key, q_val in month_map.items():\n",
    "                            if month_str.startswith(key):\n",
    "                                quarter = q_val\n",
    "                                break\n",
    "                        print(f\"  ✅ Parsed as: Year={year}, Quarter={quarter}\")\n",
    "                    else:\n",
    "                        print(\"  ❌ ERROR: Could not find the date string on the page.\")\n",
    "                        \n",
    "                    # --- Step 4: Table Extraction ---\n",
    "                    print(\"\\n--- [Step 4: Extracting Table from Page] ---\")\n",
    "                    table = page.extract_table({\n",
    "                        \"vertical_strategy\": \"lines\", \"horizontal_strategy\": \"text\",\n",
    "                        \"text_x_tolerance\": 2, \"text_y_tolerance\": 2,\n",
    "                    })\n",
    "                    if not table:\n",
    "                        print(\"  ❌ ERROR: pdfplumber.extract_table() returned None. No table found with current settings.\")\n",
    "                    else:\n",
    "                        print(f\"  ✅ Table found with {len(table)} rows.\")\n",
    "                        print(\"  - Printing full extracted table for review:\")\n",
    "                        # Use pandas to display the table cleanly\n",
    "                        df_display = pd.DataFrame(table)\n",
    "                        print(df_display.to_string())\n",
    "\n",
    "                        # --- Step 5: Header Row Detection ---\n",
    "                        print(\"\\n--- [Step 5: Finding Header Row] ---\")\n",
    "                        header_indices = {}\n",
    "                        for r_idx, r in reversed(list(enumerate(table))):\n",
    "                            row_str = \" \".join(filter(None, [str(s).replace('\\n', ' ') for s in r]))\n",
    "                            if \"Personal Accident\" in row_str and \"Travel\" in row_str and \"Health\" in row_str:\n",
    "                                print(f\"  - Potential header found in table row {r_idx}: '{row_str}'\")\n",
    "                                for c_idx, cell in enumerate(r):\n",
    "                                    if cell:\n",
    "                                        clean_cell = cell.replace('\\n', ' ').strip()\n",
    "                                        if \"Health\" == clean_cell: header_indices['health'] = c_idx\n",
    "                                        elif \"Personal Accident\" == clean_cell: header_indices['personal_accident'] = c_idx\n",
    "                                        elif \"Travel Insurance\" == clean_cell: header_indices['travel'] = c_idx\n",
    "                                        elif \"Total\" in clean_cell: header_indices['total'] = c_idx\n",
    "                                if 'health' in header_indices and 'personal_accident' in header_indices:\n",
    "                                    print(f\"  ✅ Header indices mapped: {header_indices}\")\n",
    "                                    break\n",
    "                        if not header_indices:\n",
    "                             print(\"  ❌ ERROR: Could not find the header row containing 'Health', 'Personal Accident', etc.\")\n",
    "\n",
    "                        # --- Step 6: Data Row Detection ---\n",
    "                        print(\"\\n--- [Step 6: Finding 'Gross Direct Premium' Data Row] ---\")\n",
    "                        data_row_found = False\n",
    "                        if header_indices:\n",
    "                            for r_idx, r in enumerate(table):\n",
    "                                if r and any(cell and \"Gross Direct Premium\" in str(cell) for cell in r):\n",
    "                                    data_row_found = True\n",
    "                                    print(f\"  ✅ Found 'Gross Direct Premium' in table row {r_idx}.\")\n",
    "                                    print(f\"  - Full data row content: {r}\")\n",
    "                                    \n",
    "                                    # --- Step 7: Final Value Extraction ---\n",
    "                                    print(\"\\n--- [Step 7: Extracting Final Values] ---\")\n",
    "                                    health_val = clean_value(r[header_indices.get('health')])\n",
    "                                    pa_val = clean_value(r[header_indices.get('personal_accident')])\n",
    "                                    travel_val = clean_value(r[header_indices.get('travel')])\n",
    "                                    total_val = clean_value(r[header_indices.get('total')])\n",
    "                                    print(f\"    - Health: '{r[header_indices.get('health')]}' -> {health_val}\")\n",
    "                                    print(f\"    - Personal Accident: '{r[header_indices.get('personal_accident')]}' -> {pa_val}\")\n",
    "                                    print(f\"    - Travel: '{r[header_indices.get('travel')]}' -> {travel_val}\")\n",
    "                                    print(f\"    - Total: '{r[header_indices.get('total')]}' -> {total_val}\")\n",
    "                                    break\n",
    "                            if not data_row_found:\n",
    "                                print(\"  ❌ ERROR: Could not find the 'Gross Direct Premium' data row in the table.\")\n",
    "                    break # Stop after finding the first NL-4 page\n",
    "            if not nl4_page_found:\n",
    "                print(\"  ❌ ERROR: No page containing 'FORM NL-4' and 'PREMIUM SCHEDULE' was found in the entire document.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n🚨 A FATAL SCRIPT ERROR OCCURRED: {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"🕵️  DEBUGGING COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "\n",
    "# --- 3. EXECUTION: Set the PDF file you want to debug here ---\n",
    "if __name__ == \"__main__\":\n",
    "    # ▼▼▼ CHANGE THIS FILENAME TO THE PDF YOU WANT TO TEST ▼▼▼\n",
    "    PDF_TO_DEBUG = \"Q1 2024.pdf\"\n",
    "    \n",
    "    # Construct the full path to the PDF inside the 'data' directory\n",
    "    full_pdf_path = os.path.join(DATA_DIR, PDF_TO_DEBUG)\n",
    "    \n",
    "    debug_pdf_extraction(full_pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c1e268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Processing: Q1 2024.pdf\n",
      "❌ Failed to extract data from: Q1 2024.pdf\n",
      "📄 Processing: Q1 2025.pdf\n",
      "❌ Failed to extract data from: Q1 2025.pdf\n",
      "📄 Processing: Q1 FY 23.pdf\n",
      "❌ Failed to extract data from: Q1 FY 23.pdf\n",
      "📄 Processing: Q2 2024.pdf\n",
      "❌ Failed to extract data from: Q2 2024.pdf\n",
      "📄 Processing: Q2 2025.pdf\n",
      "❌ Failed to extract data from: Q2 2025.pdf\n",
      "📄 Processing: Q2 FY 23.pdf\n",
      "❌ Failed to extract data from: Q2 FY 23.pdf\n",
      "📄 Processing: Q3 2024.pdf\n",
      "❌ Failed to extract data from: Q3 2024.pdf\n",
      "📄 Processing: Q3 2025.pdf\n",
      "❌ Failed to extract data from: Q3 2025.pdf\n",
      "📄 Processing: Q3 FY 23.pdf\n",
      "❌ Failed to extract data from: Q3 FY 23.pdf\n",
      "📄 Processing: Q4 2024.pdf\n",
      "❌ Failed to extract data from: Q4 2024.pdf\n",
      "📄 Processing: Q4 2025.pdf\n",
      "❌ Failed to extract data from: Q4 2025.pdf\n",
      "📄 Processing: Q4 FY 23.pdf\n",
      "❌ Failed to extract data from: Q4 FY 23.pdf\n",
      "\n",
      "Total successfully extracted: 0\n",
      "Total failed: 12\n",
      "Failed files: ['Q1 2024.pdf', 'Q1 2025.pdf', 'Q1 FY 23.pdf', 'Q2 2024.pdf', 'Q2 2025.pdf', 'Q2 FY 23.pdf', 'Q3 2024.pdf', 'Q3 2025.pdf', 'Q3 FY 23.pdf', 'Q4 2024.pdf', 'Q4 2025.pdf', 'Q4 FY 23.pdf']\n",
      "\n",
      "No data was extracted, so no file was saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "# --- 1. SETUP: Define your data and output directories ---\n",
    "BASE_DIR = os.getcwd() \n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"output\")\n",
    "\n",
    "# --- Helper function for cleaning numeric values ---\n",
    "def clean_value(text):\n",
    "    \"\"\"Cleans a string to extract a numeric value.\"\"\"\n",
    "    if text is None:\n",
    "        return 0\n",
    "    cleaned_text = re.sub(r'[^\\d.-]', '', str(text))\n",
    "    if not cleaned_text or cleaned_text == '-':\n",
    "        return 0\n",
    "    try:\n",
    "        return int(float(cleaned_text))\n",
    "    except (ValueError, TypeError):\n",
    "        return 0\n",
    "\n",
    "# --- 2. THE FINAL PARSER: With robust provider and data extraction ---\n",
    "def parse_nl4_final_robust(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts premium data from a FORM NL-4 PDF.\n",
    "    This version robustly finds the provider name on the correct page\n",
    "    and handles various formatting inconsistencies.\n",
    "    \"\"\"\n",
    "    provider = \"Unknown\"\n",
    "    month_map = {\n",
    "        'june': 'Q1', 'jun': 'Q1',\n",
    "        'september': 'Q2', 'sep': 'Q2',\n",
    "        'december': 'Q3', 'dec': 'Q3',\n",
    "        'march': 'Q4', 'mar': 'Q4'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            # Find and process the NL-4 page\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text(x_tolerance=2, layout=True) or \"\"\n",
    "                # Check if this is the correct page\n",
    "                if \"FORM NL-4\" not in page_text or \"PREMIUM SCHEDULE\" not in page_text:\n",
    "                    continue\n",
    "\n",
    "                # --- STEP 1: (FIXED) Extract Provider Name from the CORRECT page ---\n",
    "                # The provider name is usually at the top of the NL-4 schedule itself.\n",
    "                # First, try to find a line like \"Name of Insurer : [Name]\"\n",
    "                provider_match = re.search(r\"Name\\s+of\\s+(?:the\\s+)?Insurer\\s*[:\\s]+\\s*(.+)\", page_text, re.IGNORECASE)\n",
    "                if provider_match:\n",
    "                    provider = provider_match.group(1).strip()\n",
    "                else:\n",
    "                    # Fallback: Search the first few lines of the page for a company name\n",
    "                    for line in page_text.splitlines()[:5]: # Check top 5 lines\n",
    "                        if \"Insurance\" in line and (\"Ltd\" in line or \"Limited\" in line):\n",
    "                            provider = line.strip()\n",
    "                            break\n",
    "\n",
    "                # --- STEP 2: Extract Year and Quarter ---\n",
    "                year, quarter = None, None\n",
    "                date_match = re.search(r\"For\\s+the\\s+Quarter\\s+(?:Ended\\s*)?(?:on\\s|at\\s)?(?:the\\s)?\\d{0,2}(?:st|nd|rd|th)?\\s*([A-Za-z]+)[, ]+\\s*(\\d{4})\", page_text, re.IGNORECASE)\n",
    "                if date_match:\n",
    "                    month_str, year_str = date_match.group(1).lower(), date_match.group(2)\n",
    "                    year = int(year_str)\n",
    "                    for key, q_val in month_map.items():\n",
    "                        if month_str.startswith(key):\n",
    "                            quarter = q_val\n",
    "                            break\n",
    "                \n",
    "                if not year or not quarter:\n",
    "                    # If date not found on this page, something is wrong, skip page\n",
    "                    continue \n",
    "\n",
    "                # --- STEP 3: Extract Table Data ---\n",
    "                table = page.extract_table({\n",
    "                    \"vertical_strategy\": \"lines\", \"horizontal_strategy\": \"text\",\n",
    "                    \"text_x_tolerance\": 2, \"text_y_tolerance\": 2,\n",
    "                })\n",
    "                if not table:\n",
    "                    continue\n",
    "\n",
    "                # --- STEP 4: Find Header Row and Map Indices ---\n",
    "                header_indices = {}\n",
    "                header_row_found = False\n",
    "                for r in reversed(table):\n",
    "                    # Combine all cells in a row to a single string for easy searching\n",
    "                    row_str = \" \".join(filter(None, [str(s).replace('\\n', ' ') for s in r]))\n",
    "                    if \"Personal Accident\" in row_str and \"Travel\" in row_str and \"Health\" in row_str:\n",
    "                        for i, cell in enumerate(r):\n",
    "                            if cell:\n",
    "                                clean_cell = cell.replace('\\n', ' ').strip()\n",
    "                                # Map the exact header text to its column index\n",
    "                                if clean_cell == \"Health\": header_indices['health'] = i\n",
    "                                elif clean_cell == \"Personal Accident\": header_indices['personal_accident'] = i\n",
    "                                elif clean_cell == \"Travel Insurance\": header_indices['travel'] = i\n",
    "                                elif \"Total\" in clean_cell: header_indices['total'] = i\n",
    "                        \n",
    "                        if 'health' in header_indices and 'personal_accident' in header_indices and 'travel' in header_indices:\n",
    "                           header_row_found = True\n",
    "                           break\n",
    "                \n",
    "                if not header_row_found:\n",
    "                    continue\n",
    "\n",
    "                # --- STEP 5: Find Data Row and Extract Values ---\n",
    "                for r in table:\n",
    "                    if r and any(cell and \"Gross Direct Premium\" in str(cell) for cell in r):\n",
    "                        # Use the mapped header indices to get data from the correct columns\n",
    "                        health_val = clean_value(r[header_indices.get('health')])\n",
    "                        pa_val = clean_value(r[header_indices.get('personal_accident')])\n",
    "                        travel_val = clean_value(r[header_indices.get('travel')])\n",
    "                        total_val = clean_value(r[header_indices.get('total')])\n",
    "\n",
    "                        # Once found, return the result and stop processing this PDF\n",
    "                        return {\n",
    "                            \"provider\": provider,\n",
    "                            \"year\": year,\n",
    "                            \"quarter\": quarter,\n",
    "                            \"health\": health_val,\n",
    "                            \"personal_accident\": pa_val,\n",
    "                            \"travel\": travel_val,\n",
    "                            \"total\": total_val,\n",
    "                            \"source_file\": os.path.basename(pdf_path)\n",
    "                        }\n",
    "                \n",
    "                # If we found the NL-4 page but not the data, we can stop searching\n",
    "                break \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  -> An error occurred while processing {os.path.basename(pdf_path)}: {e}\")\n",
    "    \n",
    "    # Return None if no data was successfully extracted from the PDF\n",
    "    return None\n",
    "\n",
    "# --- 3. PROCESSING LOOP: Extract data from all PDFs ---\n",
    "records = []\n",
    "failed_files = []\n",
    "\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    print(f\"❌ Error: Data directory not found at '{DATA_DIR}'\")\n",
    "    print(\"Please create a 'data' directory and place your PDF files inside it.\")\n",
    "else:\n",
    "    pdf_files = sorted(glob.glob(os.path.join(DATA_DIR, \"*.pdf\")))\n",
    "    if not pdf_files:\n",
    "        print(f\"No PDF files found in '{DATA_DIR}'.\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"📄 Processing: {os.path.basename(pdf_file)}\")\n",
    "        # Use the final, robust parsing function\n",
    "        result = parse_nl4_final_robust(pdf_file)\n",
    "        if result:\n",
    "            print(f\"✅ Extracted: {result['provider']}, {result['year']} {result['quarter']}\")\n",
    "            records.append(result)\n",
    "        else:\n",
    "            print(f\"❌ Failed to extract data from: {os.path.basename(pdf_file)}\")\n",
    "            failed_files.append(os.path.basename(pdf_file))\n",
    "\n",
    "    print(f\"\\nTotal successfully extracted: {len(records)}\")\n",
    "    if failed_files:\n",
    "        print(f\"Total failed: {len(failed_files)}\")\n",
    "        print(\"Failed files:\", failed_files)\n",
    "\n",
    "# --- 4. DATAFRAME CREATION AND SAVING ---\n",
    "if records:\n",
    "    df = pd.DataFrame(records)\n",
    "    column_order = [\n",
    "        'provider', 'year', 'quarter', \n",
    "        'health', 'personal_accident', 'travel', 'total', 'source_file'\n",
    "    ]\n",
    "    df = df[column_order]\n",
    "\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "    out_csv = os.path.join(OUT_DIR, \"premium_summary_final.csv\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    \n",
    "    print(f\"\\n✅ Data successfully saved to CSV: {out_csv}\")\n",
    "    print(\"\\n--- DataFrame Preview ---\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"\\nNo data was extracted, so no file was saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ec5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
